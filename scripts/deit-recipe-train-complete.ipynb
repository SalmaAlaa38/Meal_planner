{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4343620,"sourceType":"datasetVersion","datasetId":2557062}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T13:53:18.260375Z","iopub.execute_input":"2024-08-31T13:53:18.26076Z","iopub.status.idle":"2024-08-31T13:53:18.673225Z","shell.execute_reply.started":"2024-08-31T13:53:18.26072Z","shell.execute_reply":"2024-08-31T13:53:18.671904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load datasets\nall_diets_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/All_Diets.csv')\nmediterranean_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/mediterranean.csv')\npaleo_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/paleo.csv')\nvegan_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/vegan.csv')\nketo_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/keto.csv')\ndash_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/dash.csv')\n\n# Add 'Diet_Type' column to each dataframe\nmediterranean_df['Diet_Type'] = 'Mediterranean'\npaleo_df['Diet_Type'] = 'Paleo'\nvegan_df['Diet_Type'] = 'Vegan'\nketo_df['Diet_Type'] = 'Keto'\ndash_df['Diet_Type'] = 'DASH'\n\n# Combine all dataframes\ncombined_df = pd.concat([mediterranean_df, paleo_df, vegan_df, keto_df, dash_df])\n\n# Clean data (example: drop duplicates, handle missing values)\ncombined_df.drop_duplicates(inplace=True)\ncombined_df.fillna('', inplace=True)\n\nprint(combined_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:02:39.202322Z","iopub.execute_input":"2024-08-31T14:02:39.202928Z","iopub.status.idle":"2024-08-31T14:02:39.358251Z","shell.execute_reply.started":"2024-08-31T14:02:39.202884Z","shell.execute_reply":"2024-08-31T14:02:39.356817Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Set option to display all columns\npd.set_option('display.max_columns', None)\n\n# Load your dataset (example)\ncombined_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/All_Diets.csv')\n\n# Display the DataFrame with all columns visible\nprint(combined_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:05:39.729297Z","iopub.execute_input":"2024-08-31T14:05:39.729758Z","iopub.status.idle":"2024-08-31T14:05:39.763509Z","shell.execute_reply.started":"2024-08-31T14:05:39.729716Z","shell.execute_reply":"2024-08-31T14:05:39.762291Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Set display option to show all columns\npd.set_option('display.max_columns', None)\n\n# Load datasets\npaleo_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/paleo.csv')\nmediterranean_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/mediterranean.csv')\nvegan_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/vegan.csv')\nketo_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/keto.csv')\ndash_df = pd.read_csv('/kaggle/input/healthy-diet-recipes-a-comprehensive-dataset/dash.csv')\n\n# Add 'Diet_type' column to each dataframe if not present\nmediterranean_df['Diet_type'] = 'Mediterranean'\npaleo_df['Diet_type'] = 'Paleo'\nvegan_df['Diet_type'] = 'Vegan'\nketo_df['Diet_type'] = 'Keto'\ndash_df['Diet_type'] = 'DASH'\n\n# Combine all dataframes into one\ncombined_df = pd.concat([paleo_df, mediterranean_df, vegan_df, keto_df, dash_df], ignore_index=True)\n\n# Clean the data (e.g., drop duplicates, handle missing values)\ncombined_df.drop_duplicates(inplace=True)\ncombined_df.fillna('', inplace=True)\n\n# Display the first few rows of the DataFrame to check the combined dataset\nprint(combined_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:16:31.496033Z","iopub.execute_input":"2024-08-31T14:16:31.496624Z","iopub.status.idle":"2024-08-31T14:16:31.576113Z","shell.execute_reply.started":"2024-08-31T14:16:31.49656Z","shell.execute_reply":"2024-08-31T14:16:31.574839Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Encode 'Diet_type' and 'Cuisine_type' as categorical variables\ndiet_type_encoder = LabelEncoder()\ncombined_df['Diet_type_Encoded'] = diet_type_encoder.fit_transform(combined_df['Diet_type'])\n\ncuisine_type_encoder = LabelEncoder()\ncombined_df['Cuisine_type_Encoded'] = cuisine_type_encoder.fit_transform(combined_df['Cuisine_type'])\n\n# Select numerical features\nnumerical_features = combined_df[['Protein(g)', 'Carbs(g)', 'Fat(g)']]\n\n# Standardize numerical features\nscaler = StandardScaler()\nnumerical_features_scaled = scaler.fit_transform(numerical_features)\n\n# Combine all features into a single feature set\nimport numpy as np\n\nfeatures = np.hstack((numerical_features_scaled, combined_df[['Diet_type_Encoded', 'Cuisine_type_Encoded']].values))\n\n# Define the target variable (for example, high protein recipes)\ntarget = (combined_df['Protein(g)'] > 50).astype(int)  # Example target: High protein (1) vs. Low protein (0)\n\nprint(\"Feature set and target variable prepared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:16:46.912854Z","iopub.execute_input":"2024-08-31T14:16:46.91363Z","iopub.status.idle":"2024-08-31T14:16:47.459153Z","shell.execute_reply.started":"2024-08-31T14:16:46.913574Z","shell.execute_reply":"2024-08-31T14:16:47.457823Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Initialize and train the model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:17:02.465109Z","iopub.execute_input":"2024-08-31T14:17:02.465755Z","iopub.status.idle":"2024-08-31T14:17:03.34894Z","shell.execute_reply.started":"2024-08-31T14:17:02.465709Z","shell.execute_reply":"2024-08-31T14:17:03.347855Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\ndef get_random_recipe(df, diet_type=None):\n    \"\"\"\n    Function to return a random recipe.\n    If diet_type is specified, return a random recipe from that diet.\n    \"\"\"\n    if diet_type:\n        filtered_df = df[df['Diet_type'].str.lower() == diet_type.lower()]\n    else:\n        filtered_df = df\n    \n    if not filtered_df.empty:\n        random_index = random.choice(filtered_df.index)\n        return filtered_df.loc[random_index]\n    else:\n        return \"No recipes found for the specified diet type.\"\n\n# Example usage\nprint(\"Random Vegan Recipe:\")\nprint(get_random_recipe(combined_df, diet_type='Vegan'))\n\nprint(\"\\nRandom Recipe from Any Diet:\")\nprint(get_random_recipe(combined_df))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:17:27.722123Z","iopub.execute_input":"2024-08-31T14:17:27.722553Z","iopub.status.idle":"2024-08-31T14:17:27.737867Z","shell.execute_reply.started":"2024-08-31T14:17:27.722513Z","shell.execute_reply":"2024-08-31T14:17:27.736745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n# Save the trained model to a file\njoblib.dump(model, 'diet_recipe_model.pkl')\nprint(\"Model saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:17:48.510015Z","iopub.execute_input":"2024-08-31T14:17:48.510929Z","iopub.status.idle":"2024-08-31T14:17:48.572671Z","shell.execute_reply.started":"2024-08-31T14:17:48.510882Z","shell.execute_reply":"2024-08-31T14:17:48.571542Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the saved model\nloaded_model = joblib.load('diet_recipe_model.pkl')\n\n# Use the loaded model to make predictions\nloaded_y_pred = loaded_model.predict(X_test)\nprint(f\"Loaded Model Accuracy: {accuracy_score(y_test, loaded_y_pred):.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:18:02.511542Z","iopub.execute_input":"2024-08-31T14:18:02.511961Z","iopub.status.idle":"2024-08-31T14:18:02.577395Z","shell.execute_reply.started":"2024-08-31T14:18:02.511923Z","shell.execute_reply":"2024-08-31T14:18:02.576058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\ndef provide_random_recipe(df, model=None, features=None, use_model=False):\n    \"\"\"\n    Function to provide a random recipe.\n    If use_model is True, use the trained model to filter recipes based on high protein content or other criteria.\n    \n    Parameters:\n    - df: DataFrame containing recipes.\n    - model: Trained machine learning model (optional).\n    - features: Features used for model prediction (optional).\n    - use_model: Boolean flag to indicate whether to use the model for filtering.\n    \n    Returns:\n    - A randomly selected recipe.\n    \"\"\"\n    if use_model and model is not None and features is not None:\n        # Predict high protein recipes using the model\n        predictions = model.predict(features)\n        high_protein_recipes = df[predictions == 1]  # Filter recipes with high protein\n        \n        if not high_protein_recipes.empty:\n            random_index = random.choice(high_protein_recipes.index)\n            return high_protein_recipes.loc[random_index]\n        else:\n            return \"No high protein recipes found.\"\n    else:\n        # Return a random recipe from the entire dataset\n        random_index = random.choice(df.index)\n        return df.loc[random_index]\n\n# Example usage\nrandom_recipe = provide_random_recipe(combined_df)\nprint(\"Random Recipe:\\n\", random_recipe)\n\n# Example usage with model\nrandom_high_protein_recipe = provide_random_recipe(combined_df, model=model, features=features, use_model=True)\nprint(\"\\nRandom High Protein Recipe:\\n\", random_high_protein_recipe)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T14:19:31.255106Z","iopub.execute_input":"2024-08-31T14:19:31.255565Z","iopub.status.idle":"2024-08-31T14:19:31.320477Z","shell.execute_reply.started":"2024-08-31T14:19:31.255525Z","shell.execute_reply":"2024-08-31T14:19:31.319106Z"},"trusted":true},"outputs":[],"execution_count":null}]}