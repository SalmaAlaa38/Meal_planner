{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_file_path = \"../meal_planner/full_recipe_dataset_final_version.csv\"\n",
    "recipe_dataset = pd.read_csv(recipe_file_path)\n",
    "\n",
    "user_file_path = \"../meal_planner/user_profile_final_version_2.csv\"\n",
    "user_dataset = pd.read_csv(user_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recipe_id', '30_mins', 'breakfast', 'cookies', 'cottage_cheese',\n",
       "       'desserts', 'dinner', 'lunch', 'meal_prep', 'sauces_seasoning',\n",
       "       'sides_appetizers', 'calories', 'carbohydrates', 'cholesterol',\n",
       "       'cook_time', 'course', 'cuisine', 'description', 'fat', 'fiber',\n",
       "       'full_name', 'image_url', 'ingredient_count', 'ingredients',\n",
       "       'instructions', 'monounsaturated_fat', 'notes', 'polyunsaturated_fat',\n",
       "       'potassium', 'prep_time', 'protein', 'saturated_fat', 'serving',\n",
       "       'sodium', 'sugar', 'title', 'dairy_free', 'gluten_free', '4th_july',\n",
       "       'christmas', 'cinco_de_mayo', 'easter', 'fathers_day', 'labor_day',\n",
       "       'memorial_day', 'mothers_day', 'thanksgiving', 'valentienes_day',\n",
       "       'beef', 'chicken', 'pork', 'turkey', 'seafood', 'fall', 'pumpkin',\n",
       "       'spring', 'summer', 'winter', 'protein_type', 'meal_type', 'holiday',\n",
       "       'season', 'ingredient_names', 'diet_type', 'diet_prefrences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = ['recipe_id', '30_mins', 'breakfast', 'cookies', 'cottage_cheese',\n",
    "       'desserts', 'dinner', 'lunch', 'meal_prep', 'sauces_seasoning',\n",
    "       'sides_appetizers', 'cholesterol',\n",
    "       'cook_time', 'course', 'description', 'fiber',\n",
    "       'full_name', 'image_url', 'ingredient_count', 'ingredients',\n",
    "       'instructions', 'monounsaturated_fat', 'notes', 'polyunsaturated_fat',\n",
    "       'potassium', 'prep_time', 'saturated_fat', 'serving',\n",
    "       'sodium', 'sugar', 'dairy_free', 'gluten_free', '4th_july',\n",
    "       'christmas', 'cinco_de_mayo', 'easter', 'fathers_day', 'labor_day',\n",
    "       'memorial_day', 'mothers_day', 'thanksgiving', 'valentienes_day',\n",
    "       'beef', 'chicken', 'pork', 'turkey', 'seafood', 'fall', 'pumpkin',\n",
    "       'spring', 'summer', 'winter', 'holiday',\n",
    "       'season']\n",
    "recipe_dataset = recipe_dataset.drop(unwanted_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calories', 'carbohydrates', 'cuisine', 'fat', 'protein', 'title',\n",
       "       'protein_type', 'meal_type', 'ingredient_names', 'diet_type',\n",
       "       'diet_prefrences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_dataset.to_csv(\"../meal_planner/model_recipe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'age', 'gender', 'height', 'weight', 'activity_level',\n",
       "       'dietary_preference', 'BMI', 'obesity_level', 'goal', 'TDEE',\n",
       "       'daily_cals_goal', 'protein_g', 'carbs_g', 'fats_g', 'fav_cuisine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = ['user_id', 'age', 'gender', 'height', 'weight', 'activity_level',\n",
    "       'dietary_preference', 'BMI', 'obesity_level', 'goal', 'TDEE']\n",
    "user_dataset = user_dataset.drop(unwanted_columns, axis=1)\n",
    "user_dataset [\"fav_cuisine\"] = user_dataset[\"fav_cuisine\"].apply(lambda x: [] if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dataset.to_csv(\"../meal_planner/model_user.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\2417004841.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user['fav_cuisine'] = user['fav_cuisine'] if isinstance(user['fav_cuisine'], list) else []\n",
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\2417004841.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  recipes['calories'].fillna(recipes['calories'].median(), inplace=True)\n",
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\2417004841.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  recipes['calorie_diff'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Meals:\n",
      "                                title  calories meal_type diet_prefrences  \\\n",
      "240            Instant Pot Short Ribs     667.0                             \n",
      "119  Cajun Sausage and Potato Skillet     573.0                             \n",
      "320            Marry Me Chicken Pasta     539.0                             \n",
      "28           Macro Friendly Chili Mac     499.0                             \n",
      "78                     Fajita Burgers     496.0                             \n",
      "\n",
      "          score  \n",
      "240 -325.233333  \n",
      "119 -375.573333  \n",
      "320 -414.863333  \n",
      "28  -435.493333  \n",
      "78  -441.413333  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # Safe parsing for list-like strings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load datasets\n",
    "recipes = recipe_dataset.copy()\n",
    "users = user_dataset.copy()\n",
    "\n",
    "# Function to safely process list-like columns\n",
    "def process_list_column(col):\n",
    "    return col.apply(lambda x: ','.join(ast.literal_eval(x)) if isinstance(x, str) and x.startswith(\"[\") else '')\n",
    "\n",
    "recipes['meal_type'] = process_list_column(recipes['meal_type'])\n",
    "recipes['diet_prefrences'] = process_list_column(recipes['diet_prefrences'])\n",
    "\n",
    "# Select a user (first user for simplicity)\n",
    "user = users.iloc[0]\n",
    "\n",
    "# Ensure fav_cuisine is a list (if empty, set to an empty list)\n",
    "user['fav_cuisine'] = user['fav_cuisine'] if isinstance(user['fav_cuisine'], list) else []\n",
    "\n",
    "# Fill missing values in 'calories' column\n",
    "recipes['calories'].fillna(recipes['calories'].median(), inplace=True)\n",
    "\n",
    "# Compute calorie difference and match favorite cuisine\n",
    "recipes['calorie_diff'] = abs(recipes['calories'] - user['daily_cals_goal'] / 3)\n",
    "\n",
    "# Fill missing values in 'calorie_diff'\n",
    "recipes['calorie_diff'].fillna(0, inplace=True)\n",
    "\n",
    "# Cuisine match (convert to int)\n",
    "recipes['fav_cuisine_match'] = recipes['cuisine'].apply(lambda x: int(x in user['fav_cuisine']))\n",
    "\n",
    "# Prepare features and target\n",
    "X = recipes[['calories', 'protein', 'carbohydrates', 'fat', 'meal_type', 'diet_prefrences', 'fav_cuisine_match']]\n",
    "y = -recipes['calorie_diff']  # Negative to prioritize lower calorie difference\n",
    "\n",
    "# Ensure y has no NaN values\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "categorical_features = ['meal_type', 'diet_prefrences']\n",
    "numerical_features = ['calories', 'protein', 'carbohydrates', 'fat', 'fav_cuisine_match']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train a model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data and fit the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)  # No more NaN errors!\n",
    "\n",
    "# Predict scores for recommendation\n",
    "recipes['score'] = model.predict(X)\n",
    "\n",
    "# Recommend top 5 meals\n",
    "recommendations = recipes.sort_values(by='score', ascending=False).head(5)\n",
    "\n",
    "print(\"Recommended Meals:\")\n",
    "print(recommendations[['title', 'calories', 'meal_type', 'diet_prefrences', 'score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\3717306250.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user['fav_cuisine'] = user['fav_cuisine'] if isinstance(user['fav_cuisine'], list) else []\n",
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\3717306250.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  recipes['calories'].fillna(recipes['calories'].median(), inplace=True)\n",
      "C:\\Users\\saadt\\AppData\\Local\\Temp\\ipykernel_8744\\3717306250.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  recipes['calorie_diff'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 67\u001b[0m\n\u001b[0;32m     61\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     62\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     63\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m     64\u001b[0m ])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Split data and fit the model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)  \u001b[38;5;66;03m# No more NaN errors!\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Predict scores for recommendation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saadt\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\saadt\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\saadt\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2485\u001b[0m     )\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import ast  # Safe parsing for list-like strings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load datasets\n",
    "recipes = recipe_dataset.copy()\n",
    "users = user_dataset.copy()\n",
    "\n",
    "# Function to safely process list-like columns\n",
    "def process_list_column(col):\n",
    "    return col.apply(lambda x: ','.join(ast.literal_eval(x)) if isinstance(x, str) and x.startswith(\"[\") else '')\n",
    "\n",
    "recipes['meal_type'] = process_list_column(recipes['meal_type'])\n",
    "recipes['diet_prefrences'] = process_list_column(recipes['diet_prefrences'])\n",
    "\n",
    "# Select a user (first user for simplicity)\n",
    "user = users.iloc[0]\n",
    "\n",
    "# Ensure fav_cuisine is a list (if empty, set to an empty list)\n",
    "user['fav_cuisine'] = user['fav_cuisine'] if isinstance(user['fav_cuisine'], list) else []\n",
    "\n",
    "# Fill missing values in 'calories' column\n",
    "recipes['calories'].fillna(recipes['calories'].median(), inplace=True)\n",
    "\n",
    "# Compute calorie difference and match favorite cuisine\n",
    "recipes['calorie_diff'] = abs(recipes['calories'] - user['daily_cals_goal'] / 4)\n",
    "\n",
    "# Fill missing values in 'calorie_diff'\n",
    "recipes['calorie_diff'].fillna(0, inplace=True)\n",
    "\n",
    "# Cuisine match (convert to int)\n",
    "recipes['fav_cuisine_match'] = recipes['cuisine'].apply(lambda x: int(x in user['fav_cuisine']))\n",
    "\n",
    "# Filter recipes based on diet preferences\n",
    "diet_preferences = set(user.get('diet_preferences', []))\n",
    "recipes = recipes[recipes['diet_prefrences'].apply(lambda x: bool(set(x.split(',')) & diet_preferences))]\n",
    "\n",
    "# Prepare features and target\n",
    "X = recipes[['calories', 'protein', 'carbohydrates', 'fat', 'meal_type', 'diet_prefrences', 'fav_cuisine_match']]\n",
    "y = -recipes['calorie_diff']  # Negative to prioritize lower calorie difference\n",
    "\n",
    "# Ensure y has no NaN values\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "categorical_features = ['meal_type', 'diet_prefrences']\n",
    "numerical_features = ['calories', 'protein', 'carbohydrates', 'fat', 'fav_cuisine_match']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train a model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data and fit the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)  # No more NaN errors!\n",
    "\n",
    "# Predict scores for recommendation\n",
    "recipes['score'] = model.predict(X)\n",
    "\n",
    "# Recommend top 4 meals\n",
    "recommendations = recipes.sort_values(by='score', ascending=False).head(4)\n",
    "\n",
    "print(\"Recommended Meals:\")\n",
    "print(recommendations[['title', 'calories', 'meal_type', 'diet_prefrences', 'score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
