{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['food_name', 'diet_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load classifier dataset\n",
    "classifier_dataset_file_path = \"../output/classifier_final_version.csv\"\n",
    "classifier_dataset = pd.read_csv(classifier_dataset_file_path)\n",
    "\n",
    "print(classifier_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            food_name   diet_type\n",
      "0      Alaskan salmon  Omnivorous\n",
      "1             Almonds       Vegan\n",
      "2            Amaranth       Vegan\n",
      "3           Anchovies  Omnivorous\n",
      "4           Asparagus       Vegan\n",
      "..                ...         ...\n",
      "115           Tilapia  Omnivorous\n",
      "116  Tuna (Yellowfin)  Omnivorous\n",
      "117     Turkey breast  Omnivorous\n",
      "118           Walnuts       Vegan\n",
      "119        Wheat Germ       Vegan\n",
      "\n",
      "[120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Doublicate the classification dataset to get higher accuracy\n",
    "classifier_duplicate = classifier_dataset.copy()\n",
    "df_compined = pd.concat([classifier_dataset, classifier_duplicate], ignore_index=True)\n",
    "print(df_compined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "input = df_compined['food_name']\n",
    "label =df_compined['diet_type']\n",
    "\n",
    "# Tokenize text features\n",
    "vectorizer = TfidfVectorizer()\n",
    "input_vectorized = vectorizer.fit_transform(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test =train_test_split(input_vectorized, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/food_vectorizer.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and vectorizer\n",
    "import joblib\n",
    "joblib.dump(model, '../models/food_classifier_model.pkl')\n",
    "joblib.dump(vectorizer, '../models/food_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
